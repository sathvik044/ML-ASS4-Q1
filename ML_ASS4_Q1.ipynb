{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+a8ya5vxopUUeW1ycBEU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathvik044/ML-ASS4-Q1/blob/main/ML_ASS4_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLvnSLUS8Jc4",
        "outputId": "cdf4d625-e112-4884-ef35-2a9a98d9572f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14, 6)\n",
            "   Day   Outlook Temp. Humidity    Wind Decision\n",
            "0    1     Sunny   Hot     High    Weak       No\n",
            "1    2     Sunny   Hot     High  Strong       No\n",
            "2    3  Overcast   Hot     High    Weak      Yes\n",
            "3    4      Rain  Mild     High    Weak      Yes\n",
            "4    5      Rain  Cool   Normal    Weak      Yes\n",
            "Decision Tree: {'Day': [(1, 'No'), (2, 'No'), (3, 'Yes'), (4, 'Yes'), (5, 'Yes'), (6, 'No'), (7, 'Yes'), (8, 'No'), (9, 'Yes'), (10, 'Yes'), (11, 'Yes'), (12, 'Yes'), (13, 'Yes'), (14, 'No')]}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Enjoy sports.csv')\n",
        "\n",
        "# Display shape and first few rows of the dataset\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Function to find unique values in an attribute\n",
        "def values(attr):\n",
        "    l = []\n",
        "    for x in attr:\n",
        "        if x not in l:\n",
        "            l.append(x)\n",
        "    return l\n",
        "\n",
        "# Function to calculate entropy\n",
        "def Entropy(data):\n",
        "    d = data.iloc[:, -1]  # The target column\n",
        "    d = d.value_counts()\n",
        "    s = 0\n",
        "    for v in d.keys():\n",
        "        p = d[v] / sum(d)\n",
        "        s -= p * np.log2(p)\n",
        "    return s\n",
        "\n",
        "# Function to calculate Information Gain\n",
        "def IG(data, A):\n",
        "    Es = Entropy(data)  # Entropy of the whole dataset\n",
        "    val = values(data[A])  # Unique values of the feature\n",
        "    s_c = data[A].value_counts()  # Value counts of the feature\n",
        "    s_v = []\n",
        "\n",
        "    for v in range(len(val)):\n",
        "        ds = data[data[A] == val[v]]  # Subset where the feature equals a particular value\n",
        "        s = 0\n",
        "        for res in values(data.iloc[:, -1]):  # Iterate over all possible results\n",
        "            try:\n",
        "                pi = ds.iloc[:, -1].value_counts()[res] / len(ds)\n",
        "                s -= pi * np.log2(pi)\n",
        "            except:\n",
        "                s = 0\n",
        "        s_v.append(s)\n",
        "\n",
        "    for i in range(len(val)):\n",
        "        Es = Es - s_c[val[i]] * s_v[i] / sum(s_c)  # Weighted sum of entropy for all splits\n",
        "\n",
        "    return Es\n",
        "\n",
        "# Node class to represent each node in the tree\n",
        "class Node():\n",
        "    def _init_(self, name=None, attr=None):\n",
        "        self.name = name\n",
        "        self.attr = attr\n",
        "\n",
        "    def call_(self):\n",
        "        return self.name\n",
        "\n",
        "# Function to create a node by finding the best feature using Information Gain\n",
        "def DTNode(data, features_used):\n",
        "    node = Node()\n",
        "    IGmax = 0\n",
        "    v_best = None\n",
        "    val_list = [v for v in values(data)[:-1] if v not in features_used]\n",
        "\n",
        "    if val_list != []:\n",
        "        for v in val_list:\n",
        "            if IG(data, v) > IGmax:\n",
        "                IGmax = IG(data, v)\n",
        "                v_best = v\n",
        "\n",
        "        if v_best:\n",
        "            features_used.append(v_best)\n",
        "            node.name = v_best\n",
        "            node.attr = values(data[v_best])\n",
        "\n",
        "            return node\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# Recursive function to build the decision tree\n",
        "def DTclassifier(data, features_used):\n",
        "    root = DTNode(data, features_used)\n",
        "\n",
        "    DT_dict = {}\n",
        "    if root != None:\n",
        "        item = []\n",
        "        for attr in root.attr:\n",
        "            dataN = data[data[root.name] == attr]\n",
        "            if Entropy(dataN) == 0:  # If entropy is 0, it's a leaf node\n",
        "                item.append((attr, values(dataN.iloc[:, -1])[0]))\n",
        "            else:\n",
        "                dt = DTclassifier(dataN, features_used)  # Recursive call\n",
        "                item.append((attr, dt))\n",
        "        DT_dict[root.name] = item\n",
        "    return DT_dict\n",
        "\n",
        "# Fix: Call the classifier and print the decision tree\n",
        "features_used = []\n",
        "decision_tree = DTclassifier(df, features_used)\n",
        "print(\"Decision Tree:\", decision_tree)"
      ]
    }
  ]
}